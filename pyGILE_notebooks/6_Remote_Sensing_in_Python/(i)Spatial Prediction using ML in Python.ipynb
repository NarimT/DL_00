{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27b54615",
   "metadata": {},
   "source": [
    "-------------\n",
    "```{admonition} Learning Objectives\n",
    "  - Implement machine learning workflows for spatial prediction using sklearn and rasterio\n",
    "  - Create supervised and unsupervised land cover classifications from raster data\n",
    "  - Apply cross-validation and hyperparameter tuning for spatial datasets\n",
    "  - Handle time series raster data for temporal analysis\n",
    "  - Use sklearn pipelines for preprocessing and model training\n",
    "\n",
    "```\n",
    "--------------\n",
    "\n",
    "\n",
    "# Spatial Prediction using Machine Learning with Python\n",
    "\n",
    "## Land Use Classification using Rasterio, Rioxarray & Sklearn\n",
    "\n",
    "Land cover classification is a fundamental application of machine learning in remote sensing. This tutorial demonstrates how to train ML models using raster data, combining rasterio for data handling, sklearn for machine learning, and custom functions for spatial processing.\n",
    "\n",
    "### Supervised Classification Workflow\n",
    "\n",
    "Supervised classification requires training data with known land cover labels. This example uses polygons representing different land cover classes ['water','crop','tree','developed'] and employs sklearn's LabelEncoder to convert text labels to integer categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38545ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels = gpd.read_file('../../pygis/data/LC08_L1TP_224078_20200518_20200518_01_RT_polygons.gpkg')\n",
    "labels['lc'] = le.fit(labels.name).transform(labels.name)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7a1353",
   "metadata": {},
   "source": [
    "### Building ML Pipelines for Spatial Data\n",
    "\n",
    "Sklearn pipelines provide a structured approach to data processing and model training. This pipeline includes standard preprocessing steps and a classification algorithm:\n",
    "\n",
    " * `StandardScaler`: Normalizes variables by removing mean and scaling to unit variance\n",
    " * `PCA`: Reduces dimensionality through Principal Component Analysis\n",
    " * `GaussianNB`: Applies Gaussian Naive Bayes for efficient classification\n",
    "\n",
    "The custom `fit_raster` function extracts training data from raster pixels within labeled polygons, then fits the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91907fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.features import geometry_mask\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "def fit_raster(raster_path, pipeline, labels, col='lc'):\n",
    "    \"\"\"Extract training data from raster and fit pipeline.\"\"\"\n",
    "    with rasterio.open(raster_path) as ds:\n",
    "        transform = ds.transform\n",
    "        data = ds.read()  # Shape: (bands, height, width)\n",
    "        height, width = data.shape[1], data.shape[2]\n",
    "    \n",
    "    # Resample to 150m\n",
    "    with rioxarray.open_rasterio(raster_path) as src:\n",
    "        src = src.rio.reproject(src.rio.crs, resolution=150)\n",
    "        data = src.to_numpy()\n",
    "        transform = src.rio.transform()\n",
    "        height, width = src.shape[1], src.shape[2]\n",
    "    \n",
    "    # Reshape to (samples, bands)\n",
    "    X = data.transpose(1, 2, 0).reshape(-1, data.shape[0])\n",
    "    \n",
    "    # Extract pixels and labels per polygon\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for idx, row in labels.iterrows():\n",
    "        geom = row.geometry\n",
    "        label = row[col]\n",
    "        mask = geometry_mask([geom], (height, width), transform, invert=True)\n",
    "        X_train.append(X[mask.ravel()])\n",
    "        y_train.append(np.full(np.sum(mask), label, dtype=int))\n",
    "    \n",
    "    # Concatenate training data\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = np.concatenate(y_train)\n",
    "    \n",
    "    if len(X_train) == 0:\n",
    "        raise ValueError(\"No pixels found under label polygons. Check polygon bounds or CRS.\")\n",
    "    if len(X_train) != len(y_train):\n",
    "        raise ValueError(f\"Inconsistent samples: X_train={len(X_train)}, y_train={len(y_train)}\")\n",
    "    if len(X_train) < 10:\n",
    "        raise ValueError(f\"Too few samples ({len(X_train)}) for cross-validation. Increase polygon sizes.\")\n",
    "    \n",
    "    # Check class distribution\n",
    "    unique_classes, counts = np.unique(y_train, return_counts=True)\n",
    "    class_dist = dict(zip(unique_classes, counts))\n",
    "    print(\"Class distribution in y_train:\", class_dist)\n",
    "    if len(unique_classes) < 3:\n",
    "        raise ValueError(f\"Only {len(unique_classes)} classes found in y_train. Expected 3. Increase polygon sizes.\")\n",
    "    for cls, count in class_dist.items():\n",
    "        if count < 5:\n",
    "            print(f\"Warning: Class {cls} has only {count} samples. Consider increasing polygon size.\")\n",
    "    \n",
    "    # Convert to xarray.Dataset for sklearn_xarray\n",
    "    n_samples, n_features = X_train.shape\n",
    "    X_da = xr.DataArray(\n",
    "        X_train,\n",
    "        coords={'sample': np.arange(n_samples), 'feature': np.arange(n_features)},\n",
    "        dims=['sample', 'feature']\n",
    "    )\n",
    "    y_da = xr.DataArray(\n",
    "        y_train,\n",
    "        coords={'sample': np.arange(n_samples)},\n",
    "        dims=['sample']\n",
    "    )\n",
    "    dataset = xr.Dataset({'X': X_da, 'y': y_da})\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    return X, dataset, pipeline\n",
    "\n",
    "def predict_raster(raster_path, X, pipeline):\n",
    "    \"\"\"Predict classes for entire raster.\"\"\"\n",
    "    y_pred = pipeline.predict(X)\n",
    "    \n",
    "    with rasterio.open(raster_path) as ds:\n",
    "        profile = ds.profile\n",
    "    \n",
    "    with rioxarray.open_rasterio(raster_path) as src:\n",
    "        src = src.rio.reproject(src.rio.crs, resolution=150)\n",
    "        height, width = src.shape[1], src.shape[2]\n",
    "    \n",
    "    y_pred = y_pred.reshape(height, width)\n",
    "    y_da = xr.DataArray(\n",
    "        y_pred,\n",
    "        coords={'y': np.arange(height), 'x': np.arange(width)},\n",
    "        dims=['y', 'x']\n",
    "    )\n",
    "    y_da.rio.write_crs(profile['crs'])\n",
    "    y_da.rio.write_transform(src.rio.transform())\n",
    "    \n",
    "    return y_da\n",
    "\n",
    "# Load and encode labels\n",
    "le = LabelEncoder()\n",
    "labels = gpd.read_file('../../pygis/data/LC08_L1TP_224078_20200518_20200518_01_RT_polygons.gpkg')\n",
    "labels['lc'] = le.fit_transform(labels.name)\n",
    "\n",
    "# Ensure labels match raster CRS\n",
    "raster_path = '../../pygis/data/LC08_L1TP_224078_20200518_20200518_01_RT.TIF'\n",
    "with rasterio.open(raster_path) as src:\n",
    "    labels = labels.to_crs(src.crs)\n",
    "\n",
    "# Define pipeline\n",
    "pl = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "\n",
    "# Cross-validation\n",
    "cv = CrossValidatorWrapper(StratifiedKFold(n_splits=2, shuffle=True, random_state=0), dim='sample')\n",
    "gridsearch = GridSearchCV(pl, cv=cv, scoring='balanced_accuracy',\n",
    "                          param_grid={\n",
    "                              \"scaler__with_std\": [True, False],\n",
    "                              \"pca__n_components\": [1, 2, 3]\n",
    "                          })\n",
    "\n",
    "# Plotting setup\n",
    "fig, ax = plt.subplots(dpi=200, figsize=(5, 5))\n",
    "\n",
    "# Fit and predict\n",
    "X, dataset, pipe = fit_raster(raster_path, pl, labels, col=\"lc\")\n",
    "gridsearch.fit(dataset.X, dataset.y)\n",
    "print(gridsearch.cv_results_)\n",
    "print(gridsearch.best_score_)\n",
    "print(gridsearch.best_params_)\n",
    "pipe.set_params(**gridsearch.best_params_)\n",
    "y = predict_raster(raster_path, X, pipe)\n",
    "y.plot(robust=True, ax=ax)\n",
    "\n",
    "plt.tight_layout(pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282fdfde",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with GridSearchCV\n",
    "\n",
    "GridSearchCV systematically tests different parameter combinations to find optimal model settings. This example demonstrates tuning PCA components and scaling parameters while using cross-validation to prevent overfitting.\n",
    "\n",
    "The pipeline parameters are referenced using the format `(step_name)__(parameter_name)`:\n",
    "- `\"scaler__with_std\": [True, False]` - tests StandardScaler with/without standard deviation scaling\n",
    "- `\"pca__n_components\": [1, 2, 3]` - tests different numbers of principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68463c1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.features import geometry_mask\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn_xarray.model_selection import CrossValidatorWrapper\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "def fit_raster(raster_path, pipeline, labels, col='lc'):\n",
    "    \"\"\"Extract training data and fit pipeline.\"\"\"\n",
    "    with rasterio.open(raster_path) as ds:\n",
    "        transform = ds.transform\n",
    "        data = ds.read()\n",
    "        height, width = data.shape[1], data.shape[2]\n",
    "    \n",
    "    with rioxarray.open_rasterio(raster_path) as src:\n",
    "        src = src.rio.reproject(src.rio.crs, resolution=150)\n",
    "        data = src.to_numpy()\n",
    "        transform = src.rio.transform()\n",
    "        height, width = src.shape[1], src.shape[2]\n",
    "    \n",
    "    X = data.transpose(1, 2, 0).reshape(-1, data.shape[0])\n",
    "    \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for idx, row in labels.iterrows():\n",
    "        geom = row.geometry\n",
    "        label = row[col]\n",
    "        mask = geometry_mask([geom], (height, width), transform, invert=True)\n",
    "        X_train.append(X[mask.ravel()])\n",
    "        y_train.append(np.full(np.sum(mask), label, dtype=int))\n",
    "    \n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = np.concatenate(y_train)\n",
    "    \n",
    "    if len(X_train) == 0:\n",
    "        raise ValueError(\"No pixels found under label polygons. Check polygon bounds or CRS.\")\n",
    "    if len(X_train) != len(y_train):\n",
    "        raise ValueError(f\"Inconsistent samples: X_train={len(X_train)}, y_train={len(y_train)}\")\n",
    "    if len(X_train) < 5:\n",
    "        raise ValueError(f\"Too few samples ({len(X_train)}) for cross-validation. Increase polygon sizes.\")\n",
    "    \n",
    "    # Check class distribution\n",
    "    unique_classes, counts = np.unique(y_train, return_counts=True)\n",
    "    print(\"Class distribution in y_train:\", dict(zip(unique_classes, counts)))\n",
    "    if len(unique_classes) < 3:\n",
    "        print(\"Warning: Not all classes (0, 1, 2) are present in y_train. Consider larger polygons.\")\n",
    "    \n",
    "    # Convert to xarray.Dataset for sklearn_xarray\n",
    "    n_samples, n_features = X_train.shape\n",
    "    X_da = xr.DataArray(\n",
    "        X_train,\n",
    "        coords={'sample': np.arange(n_samples), 'feature': np.arange(n_features)},\n",
    "        dims=['sample', 'feature']\n",
    "    )\n",
    "    y_da = xr.DataArray(\n",
    "        y_train,\n",
    "        coords={'sample': np.arange(n_samples)},\n",
    "        dims=['sample']\n",
    "    )\n",
    "    dataset = xr.Dataset({'X': X_da, 'y': y_da})\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    return X, dataset, pipeline\n",
    "\n",
    "def predict_raster(raster_path, X, pipeline):\n",
    "    \"\"\"Predict classes for entire raster.\"\"\"\n",
    "    y_pred = pipeline.predict(X)\n",
    "    \n",
    "    with rasterio.open(raster_path) as ds:\n",
    "        profile = ds.profile\n",
    "    \n",
    "    with rioxarray.open_rasterio(raster_path) as src:\n",
    "        src = src.rio.reproject(src.rio.crs, resolution=150)\n",
    "        height, width = src.shape[1], src.shape[2]\n",
    "    \n",
    "    y_pred = y_pred.reshape(height, width)\n",
    "    y_da = xr.DataArray(\n",
    "        y_pred,\n",
    "        coords={'y': np.arange(height), 'x': np.arange(width)},\n",
    "        dims=['y', 'x']\n",
    "    )\n",
    "    y_da.rio.write_crs(profile['crs'])\n",
    "    y_da.rio.write_transform(src.rio.transform())\n",
    "    \n",
    "    return y_da\n",
    "\n",
    "# Load and encode labels\n",
    "le = LabelEncoder()\n",
    "labels = gpd.read_file('../../pygis/data/LC08_L1TP_224078_20200518_20200518_01_RT_polygons.gpkg')\n",
    "labels['lc'] = le.fit_transform(labels.name)\n",
    "\n",
    "# Ensure labels match raster CRS\n",
    "raster_path = '../../pygis/data/LC08_L1TP_224078_20200518_20200518_01_RT.TIF'\n",
    "with rasterio.open(raster_path) as src:\n",
    "    labels = labels.to_crs(src.crs)\n",
    "\n",
    "# Define pipeline\n",
    "pl = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "\n",
    "# Cross-validation\n",
    "cv = CrossValidatorWrapper(StratifiedKFold(n_splits=2), dim='sample')\n",
    "gridsearch = GridSearchCV(pl, cv=cv, scoring='balanced_accuracy',\n",
    "                          param_grid={\n",
    "                              \"scaler__with_std\": [True, False],\n",
    "                              \"pca__n_components\": [1, 2, 3]\n",
    "                          })\n",
    "\n",
    "# Plotting setup\n",
    "fig, ax = plt.subplots(dpi=200, figsize=(5, 5))\n",
    "\n",
    "# Fit and predict\n",
    "X, dataset, pipe = fit_raster(raster_path, pl, labels, col=\"lc\")\n",
    "gridsearch.fit(dataset.X, dataset.y)\n",
    "print(gridsearch.cv_results_)\n",
    "print(gridsearch.best_score_)\n",
    "print(gridsearch.best_params_)\n",
    "pipe.set_params(**gridsearch.best_params_)\n",
    "y = predict_raster(raster_path, X, pipe)\n",
    "y.plot(robust=True, ax=ax)\n",
    "\n",
    "plt.tight_layout(pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0536948",
   "metadata": {},
   "source": [
    "## Handling Missing Data in Remote Sensing\n",
    "\n",
    "Missing data is common in remote sensing due to clouds, sensor failures, or data processing artifacts. Sklearn's SimpleImputer can handle missing values by replacing them with statistical measures (mean, median, mode).\n",
    "\n",
    "For Landsat data where missing values are often represented as 0 or already masked as `np.nan`, you can integrate imputation into your pipeline:\n",
    "\n",
    "```python\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "classifier = Pipeline([\n",
    "    (\"remove_nan\", SimpleImputer(missing_values=np.nan, strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", KMeans(n_clusters=6, random_state=0)),\n",
    "])\n",
    "\n",
    "# For data with 0s as missing values:\n",
    "src = rxr.open_rasterio(raster_path).rio.write_nodata(0)\n",
    "src_masked = src.where(src != 0, np.nan)  # Convert 0s to NaN\n",
    "# Then apply the pipeline with SimpleImputer\n",
    "```\n",
    "\n",
    "Other imputation strategies include:\n",
    "- `strategy=\"median\"` - robust to outliers\n",
    "- `strategy=\"most_frequent\"` - for categorical data\n",
    "- `strategy=\"constant\"` - fill with a specified constant value\n",
    "\n",
    "%%train = np.concatenate(y_train)\n",
    "    \n",
    "    # Check lengths\n",
    "    if len(X_train) != len(y_train):\n",
    "        raise ValueError(f\"Inconsistent samples: X_train={len(X_train)}, y_train={len(y_train)}\")\n",
    "    \n",
    "    # Fit pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    return X, (X_train, y_train), pipeline\n",
    "\n",
    "def predict_raster(raster_path, X, pipeline):\n",
    "    \"\"\"Predict classes for entire raster.\"\"\"\n",
    "    y_pred = pipeline.predict(X)\n",
    "    \n",
    "    with rasterio.open(raster_path) as ds:\n",
    "        profile = ds.profile  # Get profile from rasterio dataset\n",
    "    \n",
    "    with rioxarray.open_rasterio(raster_path) as src:\n",
    "        src = src.rio.reproject(src.rio.crs, resolution=150)\n",
    "        height, width = src.shape[1], src.shape[2]\n",
    "    \n",
    "    y_pred = y_pred.reshape(height, width)\n",
    "    \n",
    "    y_da = xr.DataArray(\n",
    "        y_pred,\n",
    "        coords={'y': np.arange(height), 'x': np.arange(width)},\n",
    "        dims=['y', 'x']\n",
    "    )\n",
    "    y_da.rio.write_crs(profile['crs'])  # Set CRS\n",
    "    y_da.rio.write_transform(src.rio.transform())  # Set transform from resampled src\n",
    "    \n",
    "    return y_da\n",
    "\n",
    "Load and encode labels\n",
    "le = LabelEncoder()\n",
    "labels = gpd.read_file('../../pygis/data/LC08_L1TP_224078_20200518_20200518_01_RT_polygons.gpkg')\n",
    "labels['lc'] = le.fit_transform(labels.name)\n",
    "\n",
    "Define pipeline\n",
    "pl = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "\n",
    "Plotting setup\n",
    "fig, ax = plt.subplots(dpi=200, figsize=(5, 5))\n",
    "\n",
    "Fit and predict\n",
    "X, Xy, clf = fit_raster('../../pygis/data/LC08_L1TP_224078_20200518_20200518_01_RT.TIF', pl, labels, col=\"lc\")\n",
    "y = predict_raster('../../pygis/data/LC08_L1TP_224078_20200518_20200518_01_RT.TIF', X, clf)\n",
    "y.plot(robust=True, ax=ax)\n",
    "\n",
    "plt.tight_layout(pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debed9de",
   "metadata": {},
   "source": [
    "### Streamlined Fit and Predict Workflow\n",
    "\n",
    "The `fit_predict_raster` function combines training and prediction into a single operation, making it convenient for rapid prototyping and testing different classification approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783deceb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.features import geometry_mask\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "def fit_predict_raster(raster_path, pipeline, labels, col='lc'):\n",
    "    \"\"\"Combine fit and predict for supervised classification.\"\"\"\n",
    "    # Read and resample raster\n",
    "    with rasterio.open(raster_path) as ds:\n",
    "        transform = ds.transform\n",
    "        data = ds.read()  # Shape: (bands, height, width)\n",
    "        height, width = data.shape[1], data.shape[2]\n",
    "        profile = ds.profile\n",
    "    \n",
    "    with rioxarray.open_rasterio(raster_path) as src:\n",
    "        src = src.rio.reproject(src.rio.crs, resolution=150)\n",
    "        data = src.to_numpy()\n",
    "        transform = src.rio.transform()\n",
    "        height, width = src.shape[1], src.shape[2]\n",
    "    \n",
    "    # Reshape to (samples, bands)\n",
    "    X = data.transpose(1, 2, 0).reshape(-1, data.shape[0])\n",
    "    \n",
    "    # Extract pixels and labels per polygon\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for idx, row in labels.iterrows():\n",
    "        geom = row.geometry\n",
    "        label = row[col]\n",
    "        mask = geometry_mask([geom], (height, width), transform, invert=True)\n",
    "        X_train.append(X[mask.ravel()])\n",
    "        y_train.append(np.full(np.sum(mask), label, dtype=int))\n",
    "    \n",
    "    # Concatenate training data\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = np.concatenate(y_train)\n",
    "    \n",
    "    # Check lengths\n",
    "    if len(X_train) != len(y_train):\n",
    "        raise ValueError(f\"Inconsistent samples: X_train={len(X_train)}, y_train={len(y_train)}\")\n",
    "    \n",
    "    # Fit pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = pipeline.predict(X)\n",
    "    \n",
    "    # Create output DataArray\n",
    "    y_pred = y_pred.reshape(height, width)\n",
    "    y_da = xr.DataArray(\n",
    "        y_pred,\n",
    "        coords={'y': np.arange(height), 'x': np.arange(width)},\n",
    "        dims=['y', 'x']\n",
    "    )\n",
    "    y_da.rio.write_crs(profile['crs'])\n",
    "    y_da.rio.write_transform(src.rio.transform())\n",
    "    \n",
    "    return y_da\n",
    "\n",
    "# Load and encode labels\n",
    "le = LabelEncoder()\n",
    "labels = gpd.read_file('../../pygis/data/LC08_L1TP_224078_20200518_20200518_01_RT_polygons.gpkg')\n",
    "labels['lc'] = le.fit_transform(labels.name)\n",
    "\n",
    "# Define pipeline\n",
    "pl = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "\n",
    "# Plotting setup\n",
    "fig, ax = plt.subplots(dpi=200, figsize=(5, 5))\n",
    "\n",
    "# Fit and predict\n",
    "y = fit_predict_raster('../../pygis/data/LC08_L1TP_224078_20200518_20200518_01_RT.TIF', pl, labels, col='lc')\n",
    "y.plot(robust=True, ax=ax)\n",
    "\n",
    "plt.tight_layout(pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf41e0ab",
   "metadata": {},
   "source": [
    "### Unsupervised Classification with K-Means\n",
    "\n",
    "Unsupervised classification identifies natural clusters in the data without requiring training labels. K-means clustering groups pixels with similar spectral characteristics, useful for exploratory analysis or when training data is unavailable. The analyst must later interpret and label the resulting clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72383b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def fit_predict_raster(raster_path, pipeline, labels=None, col='lc'):\n",
    "    \"\"\"Combine fit and predict for classification (unsupervised or supervised).\"\"\"\n",
    "    # Read and resample raster\n",
    "    with rasterio.open(raster_path) as ds:\n",
    "        profile = ds.profile\n",
    "    \n",
    "    with rioxarray.open_rasterio(raster_path) as src:\n",
    "        src = src.rio.reproject(src.rio.crs, resolution=150)\n",
    "        data = src.to_numpy()\n",
    "        height, width = src.shape[1], src.shape[2]\n",
    "    \n",
    "    # Reshape to (samples, bands)\n",
    "    X = data.transpose(1, 2, 0).reshape(-1, data.shape[0])\n",
    "    \n",
    "    if labels is not None:\n",
    "        # Supervised: Extract pixels and labels per polygon\n",
    "        transform = src.rio.transform()\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        for idx, row in labels.iterrows():\n",
    "            geom = row.geometry\n",
    "            label = row[col]\n",
    "            mask = geometry_mask([geom], (height, width), transform, invert=True)\n",
    "            X_train.append(X[mask.ravel()])\n",
    "            y_train.append(np.full(np.sum(mask), label, dtype=int))\n",
    "        \n",
    "        # Concatenate training data\n",
    "        X_train = np.concatenate(X_train)\n",
    "        y_train = np.concatenate(y_train)\n",
    "        \n",
    "        # Check lengths\n",
    "        if len(X_train) != len(y_train):\n",
    "            raise ValueError(f\"Inconsistent samples: X_train={len(X_train)}, y_train={len(y_train)}\")\n",
    "        \n",
    "        # Fit pipeline\n",
    "        pipeline.fit(X_train, y_train)\n",
    "    else:\n",
    "        # Unsupervised: Fit on all data\n",
    "        pipeline.fit(X)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = pipeline.predict(X)\n",
    "    \n",
    "    # Create output DataArray\n",
    "    y_pred = y_pred.reshape(height, width)\n",
    "    y_da = xr.DataArray(\n",
    "        y_pred,\n",
    "        coords={'y': np.arange(height), 'x': np.arange(width)},\n",
    "        dims=['y', 'x']\n",
    "    )\n",
    "    y_da.rio.write_crs(profile['crs'])\n",
    "    y_da.rio.write_transform(src.rio.transform())\n",
    "    \n",
    "    return y_da\n",
    "\n",
    "# Define pipeline\n",
    "cl = Pipeline([\n",
    "    ('clf', KMeans(n_clusters=6, random_state=0))\n",
    "])\n",
    "\n",
    "# Plotting setup\n",
    "fig, ax = plt.subplots(dpi=200, figsize=(5, 5))\n",
    "\n",
    "# Fit and predict (unsupervised)\n",
    "y = fit_predict_raster('../../pygis/data/LC08_L1TP_224078_20200518_20200518_01_RT.TIF', cl)\n",
    "y.plot(robust=True, ax=ax)\n",
    "\n",
    "plt.tight_layout(pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b7a96",
   "metadata": {},
   "source": [
    "## Time Series Classification\n",
    "\n",
    "Temporal analysis uses multiple acquisition dates to improve classification accuracy and detect changes over time. By stacking rasters along a time dimension using xarray.concat(), you can incorporate temporal dynamics into ML models for more robust predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4bab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.features import geometry_mask\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "def fit_predict_raster(raster_path, pipeline, labels=None, col='lc'):\n",
    "    \"\"\"Combine fit and predict for classification.\"\"\"\n",
    "    with rasterio.open(raster_path) as ds:\n",
    "        profile = ds.profile\n",
    "    \n",
    "    with rioxarray.open_rasterio(raster_path) as src:\n",
    "        src = src.rio.reproject(src.rio.crs, resolution=150)\n",
    "        data = src.to_numpy()\n",
    "        height, width = src.shape[1], src.shape[2]\n",
    "        transform = src.rio.transform()\n",
    "    \n",
    "    X = data.transpose(1, 2, 0).reshape(-1, data.shape[0])\n",
    "    \n",
    "    if labels is not None:\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        for idx, row in labels.iterrows():\n",
    "            geom = row.geometry\n",
    "            label = row[col]\n",
    "            mask = geometry_mask([geom], (height, width), transform, invert=True)\n",
    "            X_train.append(X[mask.ravel()])\n",
    "            y_train.append(np.full(np.sum(mask), label, dtype=int))\n",
    "        \n",
    "        X_train = np.concatenate(X_train)\n",
    "        y_train = np.concatenate(y_train)\n",
    "        \n",
    "        if len(X_train) == 0:\n",
    "            raise ValueError(\"No pixels found under label polygons. Check polygon bounds or CRS.\")\n",
    "        if len(X_train) != len(y_train):\n",
    "            raise ValueError(f\"Inconsistent samples: X_train={len(X_train)}, y_train={len(y_train)}\")\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = pipeline.predict(X)\n",
    "    \n",
    "    y_pred = y_pred.reshape(height, width)\n",
    "    y_da = xr.DataArray(\n",
    "        y_pred,\n",
    "        coords={'y': np.arange(height), 'x': np.arange(width)},\n",
    "        dims=['y', 'x']\n",
    "    )\n",
    "    y_da.rio.write_crs(profile['crs'])\n",
    "    y_da.rio.write_transform(transform)\n",
    "    \n",
    "    return y_da\n",
    "\n",
    "# Load and encode labels\n",
    "le = LabelEncoder()\n",
    "labels = gpd.read_file('../../pygis/data/LC08_L1TP_224078_20200518_20200518_01_RT_polygons.gpkg')\n",
    "labels['lc'] = le.fit_transform(labels.name)\n",
    "\n",
    "# Define pipeline\n",
    "pl = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "\n",
    "# Plotting setup\n",
    "fig, ax = plt.subplots(dpi=200, figsize=(5, 5))\n",
    "\n",
    "# Stack rasters\n",
    "raster_path = '../../pygis/data/LC08_L1TP_224078_20200518_20200518_01_RT.TIF'\n",
    "with rasterio.open(raster_path) as src:\n",
    "    crs = src.crs  # Get CRS for reprojection\n",
    "rasters = [\n",
    "    rioxarray.open_rasterio(raster_path).rio.reproject(dst_crs=crs, resolution=150),\n",
    "    rioxarray.open_rasterio(raster_path).rio.reproject(dst_crs=crs, resolution=150)\n",
    "]\n",
    "src = xr.concat(rasters, dim='band')\n",
    "\n",
    "# Save stacked raster to temporary file\n",
    "stacked_path = '../../pygis/data/stacked_raster.tif'\n",
    "src.rio.to_raster(stacked_path)\n",
    "\n",
    "# Ensure labels match raster CRS\n",
    "labels = labels.to_crs(crs)\n",
    "\n",
    "# Fit and predict\n",
    "y = fit_predict_raster(stacked_path, pl, labels, col='lc')\n",
    "print(y)\n",
    "y.plot(robust=True, ax=ax)\n",
    "\n",
    "plt.tight_layout(pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f71699",
   "metadata": {},
   "source": [
    "## Advanced Model Validation with Cross-Validation\n",
    "\n",
    "Rigorous model evaluation requires techniques like cross-validation to assess performance on unseen data. This approach helps identify overfitting and provides realistic estimates of model performance for spatial prediction tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721f5768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.features import geometry_mask\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn_xarray.model_selection import CrossValidatorWrapper\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "def fit_raster(raster_path, pipeline, labels, col='lc'):\n",
    "    \"\"\"Extract training data and fit pipeline.\"\"\"\n",
    "    with rasterio.open(raster_path) as ds:\n",
    "        transform = ds.transform\n",
    "        data = ds.read()\n",
    "        height, width = data.shape[1], data.shape[2]\n",
    "    \n",
    "    with rioxarray.open_rasterio(raster_path) as src:\n",
    "        src = src.rio.reproject(src.rio.crs, resolution=150)\n",
    "        data = src.to_numpy()\n",
    "        transform = src.rio.transform()\n",
    "        height, width = src.shape[1], src.shape[2]\n",
    "    \n",
    "    X = data.transpose(1, 2, 0).reshape(-1, data.shape[0])\n",
    "    \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for idx, row in labels.iterrows():\n",
    "        geom = row.geometry\n",
    "        label = row[col]\n",
    "        mask = geometry_mask([geom], (height, width), transform, invert=True)\n",
    "        pixels = np.sum(mask)\n",
    "        print(f\"Polygon {idx} ({row['name']}): {pixels} pixels\")\n",
    "        X_train.append(X[mask.ravel()])\n",
    "        y_train.append(np.full(pixels, label, dtype=int))\n",
    "    \n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
