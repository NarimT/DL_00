{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebf7fc19",
   "metadata": {},
   "source": [
    "# FCN Semantic Segmentation \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3371c7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Generating synthetic dataset: 80 images of size 128\n",
      "Dataset total=80, train=64, val=16, batch=8\n",
      "\n",
      "=== Experiment 1: FCN-32s | upsample=transpose ===\n",
      "Epoch 1/20 | tr_loss=0.6905 tr_acc=0.5476 tr_mIoU=0.2738 || val_loss=0.6857 val_acc=0.6389 val_mIoU=0.3195\n",
      "Epoch 3/20 | tr_loss=0.6552 tr_acc=0.6835 tr_mIoU=0.3417 || val_loss=0.6237 val_acc=0.7459 val_mIoU=0.3729\n",
      "Epoch 5/20 | tr_loss=0.5606 tr_acc=0.8465 tr_mIoU=0.4233 || val_loss=0.5118 val_acc=0.8953 val_mIoU=0.4476\n",
      "Epoch 7/20 | tr_loss=0.4473 tr_acc=0.9535 tr_mIoU=0.4768 || val_loss=0.4063 val_acc=0.9582 val_mIoU=0.4791\n",
      "Epoch 9/20 | tr_loss=0.3477 tr_acc=0.9770 tr_mIoU=0.4885 || val_loss=0.3171 val_acc=0.9801 val_mIoU=0.4900\n",
      "Epoch 11/20 | tr_loss=0.2697 tr_acc=0.9842 tr_mIoU=0.4921 || val_loss=0.2466 val_acc=0.9844 val_mIoU=0.4922\n",
      "Epoch 13/20 | tr_loss=0.2097 tr_acc=0.9973 tr_mIoU=0.8737 || val_loss=0.1968 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 15/20 | tr_loss=0.1639 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.1588 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 17/20 | tr_loss=0.1292 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.1284 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 19/20 | tr_loss=0.1029 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.1051 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 20/20 | tr_loss=0.0923 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0954 val_acc=1.0000 val_mIoU=1.0000\n",
      "Finished experiment in 57.8s\n",
      "\n",
      "=== Experiment 2: FCN-32s | upsample=bilinear ===\n",
      "Epoch 1/20 | tr_loss=1.2145 tr_acc=0.1948 tr_mIoU=0.0974 || val_loss=0.9848 val_acc=0.2687 val_mIoU=0.1344\n",
      "Epoch 3/20 | tr_loss=0.2535 tr_acc=0.9599 tr_mIoU=0.5424 || val_loss=0.3147 val_acc=0.9484 val_mIoU=0.7867\n",
      "Epoch 5/20 | tr_loss=0.0527 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0590 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 7/20 | tr_loss=0.0233 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0226 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 9/20 | tr_loss=0.0150 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0169 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 11/20 | tr_loss=0.0111 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0129 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 13/20 | tr_loss=0.0088 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0102 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 15/20 | tr_loss=0.0074 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0085 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 17/20 | tr_loss=0.0062 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0072 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 19/20 | tr_loss=0.0053 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0060 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 20/20 | tr_loss=0.0050 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0056 val_acc=1.0000 val_mIoU=1.0000\n",
      "Finished experiment in 57.1s\n",
      "\n",
      "=== Experiment 3: FCN-16s | upsample=transpose ===\n",
      "Epoch 1/20 | tr_loss=0.6914 tr_acc=0.5219 tr_mIoU=0.2610 || val_loss=0.6891 val_acc=0.5455 val_mIoU=0.2727\n",
      "Epoch 3/20 | tr_loss=0.6692 tr_acc=0.6258 tr_mIoU=0.3129 || val_loss=0.6514 val_acc=0.6702 val_mIoU=0.3351\n",
      "Epoch 5/20 | tr_loss=0.5903 tr_acc=0.7791 tr_mIoU=0.3895 || val_loss=0.5340 val_acc=0.8220 val_mIoU=0.4110\n",
      "Epoch 7/20 | tr_loss=0.4660 tr_acc=0.9083 tr_mIoU=0.4542 || val_loss=0.4075 val_acc=0.9374 val_mIoU=0.4687\n",
      "Epoch 9/20 | tr_loss=0.3335 tr_acc=0.9800 tr_mIoU=0.4900 || val_loss=0.2861 val_acc=0.9877 val_mIoU=0.4939\n",
      "Epoch 11/20 | tr_loss=0.2249 tr_acc=0.9949 tr_mIoU=0.4974 || val_loss=0.1986 val_acc=0.9964 val_mIoU=0.4982\n",
      "Epoch 13/20 | tr_loss=0.1495 tr_acc=0.9983 tr_mIoU=0.4991 || val_loss=0.1398 val_acc=0.9986 val_mIoU=0.4993\n",
      "Epoch 15/20 | tr_loss=0.1019 tr_acc=0.9994 tr_mIoU=0.4997 || val_loss=0.1007 val_acc=0.9998 val_mIoU=0.4999\n",
      "Epoch 17/20 | tr_loss=0.0726 tr_acc=0.9999 tr_mIoU=0.4999 || val_loss=0.0749 val_acc=0.9999 val_mIoU=0.4999\n",
      "Epoch 19/20 | tr_loss=0.0541 tr_acc=0.9999 tr_mIoU=0.4999 || val_loss=0.0579 val_acc=0.9999 val_mIoU=0.5000\n",
      "Epoch 20/20 | tr_loss=0.0474 tr_acc=0.9999 tr_mIoU=0.5000 || val_loss=0.0514 val_acc=0.9999 val_mIoU=0.5000\n",
      "Finished experiment in 58.5s\n",
      "\n",
      "=== Experiment 4: FCN-16s | upsample=bilinear ===\n",
      "Epoch 1/20 | tr_loss=0.2766 tr_acc=0.9306 tr_mIoU=0.4653 || val_loss=0.4081 val_acc=0.8804 val_mIoU=0.6589\n",
      "Epoch 3/20 | tr_loss=0.0486 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0824 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 5/20 | tr_loss=0.0141 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0161 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 7/20 | tr_loss=0.0077 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0094 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 9/20 | tr_loss=0.0056 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0064 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 11/20 | tr_loss=0.0043 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0053 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 13/20 | tr_loss=0.0035 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0043 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 15/20 | tr_loss=0.0029 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0035 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 17/20 | tr_loss=0.0026 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0031 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 19/20 | tr_loss=0.0022 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0028 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 20/20 | tr_loss=0.0020 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0025 val_acc=1.0000 val_mIoU=1.0000\n",
      "Finished experiment in 54.3s\n",
      "\n",
      "=== Experiment 5: FCN-8s | upsample=transpose ===\n",
      "Epoch 1/20 | tr_loss=0.6907 tr_acc=0.5214 tr_mIoU=0.2607 || val_loss=0.6867 val_acc=0.5501 val_mIoU=0.2750\n",
      "Epoch 3/20 | tr_loss=0.6569 tr_acc=0.6615 tr_mIoU=0.3308 || val_loss=0.6406 val_acc=0.6882 val_mIoU=0.3441\n",
      "Epoch 5/20 | tr_loss=0.5713 tr_acc=0.7569 tr_mIoU=0.3784 || val_loss=0.5282 val_acc=0.7701 val_mIoU=0.3851\n",
      "Epoch 7/20 | tr_loss=0.4454 tr_acc=0.8394 tr_mIoU=0.4197 || val_loss=0.3923 val_acc=0.8539 val_mIoU=0.4270\n",
      "Epoch 9/20 | tr_loss=0.3228 tr_acc=0.9387 tr_mIoU=0.4694 || val_loss=0.2808 val_acc=0.9576 val_mIoU=0.4788\n",
      "Epoch 11/20 | tr_loss=0.2242 tr_acc=0.9608 tr_mIoU=0.4804 || val_loss=0.1978 val_acc=0.9621 val_mIoU=0.4810\n",
      "Epoch 13/20 | tr_loss=0.1539 tr_acc=0.9778 tr_mIoU=0.4889 || val_loss=0.1387 val_acc=0.9785 val_mIoU=0.4893\n",
      "Epoch 15/20 | tr_loss=0.1072 tr_acc=0.9813 tr_mIoU=0.4906 || val_loss=0.0991 val_acc=0.9814 val_mIoU=0.4907\n",
      "Epoch 17/20 | tr_loss=0.0767 tr_acc=0.9823 tr_mIoU=0.4911 || val_loss=0.0728 val_acc=0.9828 val_mIoU=0.4914\n",
      "Epoch 19/20 | tr_loss=0.0566 tr_acc=0.9969 tr_mIoU=0.4985 || val_loss=0.0551 val_acc=0.9969 val_mIoU=0.4985\n",
      "Epoch 20/20 | tr_loss=0.0492 tr_acc=0.9969 tr_mIoU=0.4985 || val_loss=0.0486 val_acc=0.9972 val_mIoU=0.4986\n",
      "Finished experiment in 52.0s\n",
      "\n",
      "=== Experiment 6: FCN-8s | upsample=bilinear ===\n",
      "Epoch 1/20 | tr_loss=0.6854 tr_acc=0.5946 tr_mIoU=0.2973 || val_loss=0.6806 val_acc=0.5957 val_mIoU=0.2978\n",
      "Epoch 3/20 | tr_loss=0.1116 tr_acc=0.9981 tr_mIoU=0.8115 || val_loss=0.1295 val_acc=0.9838 val_mIoU=0.9606\n",
      "Epoch 5/20 | tr_loss=0.0273 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0408 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 7/20 | tr_loss=0.0141 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0165 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 9/20 | tr_loss=0.0095 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0106 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 11/20 | tr_loss=0.0075 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0084 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 13/20 | tr_loss=0.0065 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0074 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 15/20 | tr_loss=0.0053 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0061 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 17/20 | tr_loss=0.0047 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0053 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 19/20 | tr_loss=0.0040 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0046 val_acc=1.0000 val_mIoU=1.0000\n",
      "Epoch 20/20 | tr_loss=0.0038 tr_acc=1.0000 tr_mIoU=1.0000 || val_loss=0.0044 val_acc=1.0000 val_mIoU=1.0000\n",
      "Finished experiment in 53.4s\n",
      "\n",
      "=== Summary (final val metrics) ===\n",
      "mode\tupsample\tval_acc\t\tval_mIoU\tval_loss\n",
      "32s\ttranspose\t1.0000\t\t1.0000\t0.0954\n",
      "32s\tbilinear\t1.0000\t\t1.0000\t0.0056\n",
      "16s\ttranspose\t0.9999\t\t0.5000\t0.0514\n",
      "16s\tbilinear\t1.0000\t\t1.0000\t0.0025\n",
      "8s\ttranspose\t0.9972\t\t0.4986\t0.0486\n",
      "8s\tbilinear\t1.0000\t\t1.0000\t0.0044\n",
      "\n",
      "Models, plots and visualizations saved to: /Users/nariman/Desktop/Assignment_3/fcn_experiments\n",
      "Notebook/Script complete. You can increase NUM_IMAGES and EPOCHS for more reliable results.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os, random, time, csv\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# Dataset config: choose 'synthetic' or 'local'\n",
    "DATA_SOURCE = 'synthetic'   \n",
    "\n",
    "# Synthetic dataset params\n",
    "NUM_IMAGES = 80   \n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# Model & training\n",
    "NUM_CLASSES = 2   # binary synthetic masks: background (0), foreground (1)\n",
    "BACKBONE = 'resnet34'   \n",
    "MODE_LIST = ['32s','16s','8s']  \n",
    "UPSAMPLE_MODES = ['transpose','bilinear'] \n",
    "EPOCHS = 20 \n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "SAVE_DIR = 'fcn_experiments'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ImageNet normalization \n",
    "IMAGENET_MEAN = np.array([0.485,0.456,0.406], dtype=np.float32)\n",
    "IMAGENET_STD  = np.array([0.229,0.224,0.225], dtype=np.float32)\n",
    "\n",
    "\n",
    "# Minimal Dataset Loader\n",
    "\n",
    "class LocalSmallVOC(Dataset):\n",
    "   \n",
    "\n",
    "    def __init__(self, images_dir, masks_dir, size=IMG_SIZE, rgb_to_index_map=None, extensions=('jpg','jpeg','png')):\n",
    "        self.images = sorted([p for p in glob(os.path.join(images_dir, '*')) if p.split('.')[-1].lower() in extensions])\n",
    "        self.masks  = sorted([p for p in glob(os.path.join(masks_dir, '*')) if p.split('.')[-1].lower() in extensions])\n",
    "        # try to pair by basename if counts differ\n",
    "        if len(self.images) != len(self.masks):\n",
    "            imgs_by_name = {Path(p).stem: p for p in self.images}\n",
    "            masks_by_name = {Path(p).stem: p for p in self.masks}\n",
    "            common = sorted(set(imgs_by_name.keys()) & set(masks_by_name.keys()))\n",
    "            self.images = [imgs_by_name[n] for n in common]\n",
    "            self.masks  = [masks_by_name[n] for n in common]\n",
    "        assert len(self.images) == len(self.masks) and len(self.images) > 0, f\"No paired images/masks found in {images_dir}, {masks_dir}\"\n",
    "        self.size = size\n",
    "        self.rgb_to_index_map = rgb_to_index_map\n",
    "        self.img_tr = T.Compose([T.Resize((size,size)), T.ToTensor(), T.Normalize(IMAGENET_MEAN.tolist(), IMAGENET_STD.tolist())])\n",
    "        self.mask_tr = T.Compose([T.Resize((size,size), interpolation=T.InterpolationMode.NEAREST)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def _load_mask_index(self, path):\n",
    "        m = Image.open(path)\n",
    "        # palette\n",
    "        if m.mode == 'P':\n",
    "            arr = np.array(m.convert('L'), dtype=np.int64)\n",
    "            return arr\n",
    "        if m.mode == 'L':\n",
    "            return np.array(m, dtype=np.int64)\n",
    "        if m.mode == 'RGB':\n",
    "            arr = np.array(m, dtype=np.uint8)\n",
    "            if self.rgb_to_index_map is not None:\n",
    "                H,W,_ = arr.shape\n",
    "                out = np.zeros((H,W), dtype=np.int64) + 255\n",
    "                for rgb, cid in self.rgb_to_index_map.items():\n",
    "                    rgb = np.array(rgb, dtype=np.uint8)\n",
    "                    match = np.all(arr == rgb.reshape(1,1,3), axis=2)\n",
    "                    out[match] = cid\n",
    "                return out\n",
    "            else:\n",
    "                # best-effort: collapse R channel (not ideal)\n",
    "                return arr[:,:,0].astype(np.int64)\n",
    "        return np.array(m.convert('L'), dtype=np.int64)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_p = self.images[idx]\n",
    "        mask_p = self.masks[idx]\n",
    "        img = Image.open(img_p).convert('RGB')\n",
    "        mask_arr = self._load_mask_index(mask_p)\n",
    "        img_t = self.img_tr(img)\n",
    "        mask_img = Image.fromarray(mask_arr.astype(np.uint8))\n",
    "        mask_t = self.mask_tr(mask_img)\n",
    "        mask_t = torch.as_tensor(np.array(mask_t), dtype=torch.long)\n",
    "        if mask_t.dim() == 3:\n",
    "            mask_t = mask_t[...,0]\n",
    "        return img_t, mask_t\n",
    "\n",
    "\n",
    "# Synthetic dataset builder (binary shapes)\n",
    "\n",
    "def make_image_with_shape(size=IMG_SIZE, max_shapes=3):\n",
    "    img = Image.new('RGB', (size,size), (128,128,128))\n",
    "    mask = Image.new('L', (size,size), 0)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    mdraw = ImageDraw.Draw(mask)\n",
    "    n = random.randint(1, max_shapes)\n",
    "    for _ in range(n):\n",
    "        shape_type = random.choice(['rect','ellipse','triangle'])\n",
    "        x1 = random.randint(5, size//3)\n",
    "        y1 = random.randint(5, size//3)\n",
    "        x2 = random.randint(size//2, size-5)\n",
    "        y2 = random.randint(size//2, size-5)\n",
    "        color = tuple(np.random.randint(50, 230, size=3).tolist())\n",
    "        if shape_type == 'rect':\n",
    "            draw.rectangle([x1,y1,x2,y2], fill=color)\n",
    "            mdraw.rectangle([x1,y1,x2,y2], fill=1)\n",
    "        elif shape_type == 'ellipse':\n",
    "            draw.ellipse([x1,y1,x2,y2], fill=color)\n",
    "            mdraw.ellipse([x1,y1,x2,y2], fill=1)\n",
    "        else:\n",
    "            pts = [(x1,y2), ((x1+x2)//2, y1), (x2,y2)]\n",
    "            draw.polygon(pts, fill=color)\n",
    "            mdraw.polygon(pts, fill=1)\n",
    "    return np.array(img), (np.array(mask) // 255).astype(np.uint8)\n",
    "\n",
    "class SyntheticSegDataset(Dataset):\n",
    "    def __init__(self, imgs_np, masks_np, normalize=True):\n",
    "        # imgs_np: N,H,W,3 uint8; masks_np: N,H,W (0/1)\n",
    "        self.normalize = normalize\n",
    "        imgs = imgs_np.astype('float32') / 255.0\n",
    "        if normalize:\n",
    "            imgs = (imgs - IMAGENET_MEAN.reshape(1,1,3)) / IMAGENET_STD.reshape(1,1,3)\n",
    "        self.imgs = imgs\n",
    "        self.masks = masks_np.astype('int64')\n",
    "    def __len__(self): return len(self.imgs)\n",
    "    def __getitem__(self, idx):\n",
    "        im = self.imgs[idx]\n",
    "        m = self.masks[idx]\n",
    "        im_t = torch.from_numpy(im.transpose(2,0,1)).float()\n",
    "        m_t = torch.from_numpy(m).long()\n",
    "        return im_t, m_t\n",
    "\n",
    "\n",
    "# Backbone & FCN implementation\n",
    "\n",
    "def make_resnet_backbone(name='resnet34', pretrained=True):\n",
    "    # returns stages s0 (/4), s1 (/4), s2 (/8), s3 (/16), s4 (/32)\n",
    "  \n",
    "    try:\n",
    "        model = getattr(models, name)(weights='IMAGENET1K_V1' if pretrained else None)\n",
    "    except Exception:\n",
    "        # older versions\n",
    "        model = getattr(models, name)(pretrained=pretrained)\n",
    "    s0 = nn.Sequential(model.conv1, model.bn1, model.relu, model.maxpool)  # /4\n",
    "    s1 = model.layer1\n",
    "    s2 = model.layer2\n",
    "    s3 = model.layer3\n",
    "    s4 = model.layer4\n",
    "    return s0, s1, s2, s3, s4\n",
    "\n",
    "class FCNResNet(nn.Module):\n",
    "    def __init__(self, backbone_name='resnet34', num_classes=21, mode='8s', upsample_mode='bilinear'):\n",
    "        super().__init__()\n",
    "        assert mode in ['32s','16s','8s']\n",
    "        assert upsample_mode in ['transpose','bilinear']\n",
    "        self.mode = mode\n",
    "        self.upsample_mode = upsample_mode\n",
    "\n",
    "        self.s0, self.s1, self.s2, self.s3, self.s4 = make_resnet_backbone(backbone_name, pretrained=True)\n",
    "\n",
    "        self.score4 = nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "        if mode in ['16s','8s']:\n",
    "            self.score3 = nn.Conv2d(256, num_classes, kernel_size=1)\n",
    "        if mode == '8s':\n",
    "            self.score2 = nn.Conv2d(128, num_classes, kernel_size=1)\n",
    "\n",
    "        if upsample_mode == 'transpose':\n",
    "            # convtranspose layer choices chosen to approximate the upsample factors\n",
    "            self.up32 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=64, stride=32, padding=16, bias=False)\n",
    "            self.up16 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=32, stride=16, padding=8, bias=False)\n",
    "            self.up8  = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=16, stride=8, padding=4, bias=False)\n",
    "        else:\n",
    "            # use nn.Upsample modules (so they move to device with model.to(device))\n",
    "            self.up32 = nn.Upsample(scale_factor=32, mode='bilinear', align_corners=False)\n",
    "            self.up16 = nn.Upsample(scale_factor=16, mode='bilinear', align_corners=False)\n",
    "            self.up8  = nn.Upsample(scale_factor=8,  mode='bilinear', align_corners=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = self.s0(x)   # /4\n",
    "        h1 = self.s1(h0)  # /4\n",
    "        h2 = self.s2(h1)  # /8\n",
    "        h3 = self.s3(h2)  # /16\n",
    "        h4 = self.s4(h3)  # /32\n",
    "\n",
    "        s4 = self.score4(h4)\n",
    "        if self.mode == '32s':\n",
    "            out = self.up32(s4)\n",
    "            return self._match_input(out, x)\n",
    "\n",
    "        if self.mode == '16s':\n",
    "            s4_up2 = F.interpolate(s4, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "            s3 = self.score3(h3)\n",
    "            fuse = s4_up2 + s3\n",
    "            out = self.up16(fuse)\n",
    "            return self._match_input(out, x)\n",
    "\n",
    "        # mode == '8s'\n",
    "        s3 = self.score3(h3)\n",
    "        s2 = self.score2(h2)\n",
    "        s4_up2 = F.interpolate(s4, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        fuse3 = s4_up2 + s3\n",
    "        fuse3_up2 = F.interpolate(fuse3, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        fuse2 = fuse3_up2 + s2\n",
    "        out = self.up8(fuse2)\n",
    "        return self._match_input(out, x)\n",
    "\n",
    "    def _match_input(self, out, x):\n",
    "        if out.shape[2:] != x.shape[2:]:\n",
    "            out = F.interpolate(out, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Metrics: Pixel accuracy & robust mean IoU\n",
    "\n",
    "def pixel_accuracy(pred, target, ignore_index=255):\n",
    "    # pred: logits (B,C,H,W), target: (B,H,W)\n",
    "    pred_label = pred.argmax(dim=1)\n",
    "    valid = (target != ignore_index)\n",
    "    correct = (pred_label == target) & valid\n",
    "    correct_count = correct.sum().item()\n",
    "    total = valid.sum().item()\n",
    "    return correct_count / total if total > 0 else 0.0\n",
    "\n",
    "def mean_iou(pred, target, num_classes=NUM_CLASSES, ignore_index=255):\n",
    "    pred_label = pred.argmax(dim=1)\n",
    "    miou_list = []\n",
    "    for cls in range(num_classes):\n",
    "        p = (pred_label == cls)\n",
    "        t = (target == cls)\n",
    "        # mask out ignore_index in target\n",
    "        t = t & (target != ignore_index)\n",
    "        inter = (p & t).sum().item()\n",
    "        union = (p | t).sum().item()\n",
    "        if union == 0:\n",
    "            # skip class (no presence in gt & pred)\n",
    "            continue\n",
    "        miou_list.append(inter / union)\n",
    "    if len(miou_list) == 0:\n",
    "        return 0.0\n",
    "    return float(np.mean(miou_list))\n",
    "\n",
    "\n",
    "# Training & evaluation helpers\n",
    "\n",
    "def evaluate_model(model, loader, num_classes=NUM_CLASSES, ignore_index=255):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    total_miou = 0.0\n",
    "    batches = 0\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=ignore_index)\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in loader:\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            masks = masks.to(DEVICE)\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, masks)\n",
    "            total_loss += loss.item()\n",
    "            total_acc += pixel_accuracy(logits, masks, ignore_index=ignore_index)\n",
    "            total_miou += mean_iou(logits, masks, num_classes=num_classes, ignore_index=ignore_index)\n",
    "            batches += 1\n",
    "    if batches == 0:\n",
    "        return 0,0,0\n",
    "    return total_loss / batches, total_acc / batches, total_miou / batches\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    acc_sum = 0.0\n",
    "    iou_sum = 0.0\n",
    "    batches = 0\n",
    "    for imgs, masks in loader:\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        masks = masks.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(imgs)\n",
    "        loss = criterion(logits, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        acc_sum += pixel_accuracy(logits, masks)\n",
    "        iou_sum += mean_iou(logits, masks)\n",
    "        batches += 1\n",
    "    if batches == 0:\n",
    "        return 0,0,0\n",
    "    return running_loss / batches, acc_sum / batches, iou_sum / batches\n",
    "\n",
    "# Prepare dataset (local or synthetic)\n",
    "\n",
    "\n",
    "print(\"Generating synthetic dataset:\", NUM_IMAGES, \"images of size\", IMG_SIZE)\n",
    "images, masks = [], []\n",
    "for i in range(NUM_IMAGES):\n",
    "    im, m = make_image_with_shape(size=IMG_SIZE, max_shapes=3)\n",
    "    images.append(im)\n",
    "    masks.append(m)\n",
    "images = np.stack(images)        # (N,H,W,3) uint8\n",
    "masks = np.stack(masks)          # (N,H,W) 0/1\n",
    "# create dataset objects\n",
    "full_ds = SyntheticSegDataset(images, masks, normalize=True)\n",
    "\n",
    "\n",
    "# split train/val\n",
    "N = len(full_ds)\n",
    "indices = list(range(N))\n",
    "random.shuffle(indices)\n",
    "split = int(0.8 * N)\n",
    "train_idx = indices[:split]\n",
    "val_idx   = indices[split:]\n",
    "train_ds = Subset(full_ds, train_idx)\n",
    "val_ds   = Subset(full_ds, val_idx)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=1,           shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "print(f\"Dataset total={N}, train={len(train_ds)}, val={len(val_ds)}, batch={BATCH_SIZE}\")\n",
    "\n",
    "\n",
    "# Main experiments loop: for each FCN mode and upsample mode\n",
    "\n",
    "summary_rows = []\n",
    "experiment_count = 0\n",
    "for mode in MODE_LIST:\n",
    "    for up_mode in UPSAMPLE_MODES:\n",
    "        experiment_count += 1\n",
    "        print(f\"\\n=== Experiment {experiment_count}: FCN-{mode} | upsample={up_mode} ===\")\n",
    "        model = FCNResNet(backbone_name=BACKBONE, num_classes=NUM_CLASSES, mode=mode, upsample_mode=up_mode).to(DEVICE)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
    "\n",
    "        history = {'train_loss':[], 'train_acc':[], 'train_miou':[], 'val_loss':[], 'val_acc':[], 'val_miou':[]}\n",
    "\n",
    "        start_time = time.time()\n",
    "        for epoch in range(EPOCHS):\n",
    "            tr_loss, tr_acc, tr_iou = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "            va_loss, va_acc, va_iou = evaluate_model(model, val_loader, num_classes=NUM_CLASSES, ignore_index=255)\n",
    "            history['train_loss'].append(tr_loss)\n",
    "            history['train_acc'].append(tr_acc)\n",
    "            history['train_miou'].append(tr_iou)\n",
    "            history['val_loss'].append(va_loss)\n",
    "            history['val_acc'].append(va_acc)\n",
    "            history['val_miou'].append(va_iou)\n",
    "            if (epoch % 2 == 0) or (epoch == EPOCHS-1):\n",
    "                print(f\"Epoch {epoch+1}/{EPOCHS} | tr_loss={tr_loss:.4f} tr_acc={tr_acc:.4f} tr_mIoU={tr_iou:.4f} || val_loss={va_loss:.4f} val_acc={va_acc:.4f} val_mIoU={va_iou:.4f}\")\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Finished experiment in {elapsed:.1f}s\")\n",
    "\n",
    "        # save model & history\n",
    "        model_path = os.path.join(SAVE_DIR, f\"fcn_{mode}_{up_mode}.pth\")\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        # save history plot\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(history['train_loss'], label='train_loss')\n",
    "        plt.plot(history['val_loss'], label='val_loss', linestyle='--')\n",
    "        plt.title(f'Loss ({mode}, {up_mode})'); plt.legend()\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(history['val_miou'], label='val_mIoU')\n",
    "        plt.title('Validation mIoU'); plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(SAVE_DIR, f\"curve_{mode}_{up_mode}.png\"))\n",
    "        plt.close()\n",
    "\n",
    "        # evaluate final metrics\n",
    "        final_val_loss, final_val_acc, final_val_miou = evaluate_model(model, val_loader, num_classes=NUM_CLASSES)\n",
    "        summary_rows.append([mode, up_mode, final_val_loss, final_val_acc, final_val_miou, model_path])\n",
    "\n",
    "        # store results\n",
    "        results = {\n",
    "            'mode': mode, 'upsample': up_mode, 'model': model, 'history': history\n",
    "        }\n",
    "        # visualize 3 examples from val set\n",
    "        num_show = min(3, len(val_ds))\n",
    "        if num_show > 0:\n",
    "            plt.figure(figsize=(12,4*num_show))\n",
    "            with torch.no_grad():\n",
    "                for i in range(num_show):\n",
    "                    img_t, mask_t = val_ds[i]\n",
    "                    inp = img_t.unsqueeze(0).to(DEVICE)\n",
    "                    out = model(inp)\n",
    "                    pred = out.argmax(dim=1).squeeze(0).cpu().numpy()\n",
    "                    # reconstruct image for display (undo normalization)\n",
    "                    img_np = img_t.cpu().numpy().transpose(1,2,0)\n",
    "                    img_np = (img_np * IMAGENET_STD.reshape(1,1,3)) + IMAGENET_MEAN.reshape(1,1,3)\n",
    "                    img_np = np.clip(img_np, 0, 1)\n",
    "                    ax = plt.subplot(num_show, 3, i*3+1); ax.imshow(img_np); ax.set_title('Image'); ax.axis('off')\n",
    "                    ax = plt.subplot(num_show, 3, i*3+2); ax.imshow(mask_t.numpy(), cmap='gray'); ax.set_title('GT'); ax.axis('off')\n",
    "                    ax = plt.subplot(num_show, 3, i*3+3); ax.imshow(pred, cmap='gray'); ax.set_title(f'Pred ({mode},{up_mode})'); ax.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(SAVE_DIR, f'viz_{mode}_{up_mode}.png'))\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "# Save summary table CSV and print a short table\n",
    "\n",
    "summary_csv = os.path.join(SAVE_DIR, 'summary_table.csv')\n",
    "with open(summary_csv, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['mode','upsample','val_loss','val_pixel_acc','val_mIoU','model_path'])\n",
    "    for r in summary_rows:\n",
    "        writer.writerow(r)\n",
    "\n",
    "print(\"\\n=== Summary (final val metrics) ===\")\n",
    "print(\"mode\\tupsample\\tval_acc\\t\\tval_mIoU\\tval_loss\")\n",
    "for r in summary_rows:\n",
    "    print(f\"{r[0]}\\t{r[1]}\\t{r[3]:.4f}\\t\\t{r[4]:.4f}\\t{r[2]:.4f}\")\n",
    "\n",
    "print(f\"\\nModels, plots and visualizations saved to: {os.path.abspath(SAVE_DIR)}\")\n",
    "print(\"Notebook/Script complete. You can increase NUM_IMAGES and EPOCHS for more reliable results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5dff6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
